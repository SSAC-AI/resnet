{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNPgcP/mL51qy9vFTvrx2ja",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SSAC-AI/resnet/blob/main/Bottleneck_Block.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| 인자                        | 설명                                |\n",
        "| ------------------------- | --------------------------------- |\n",
        "| `in_channels`             | 입력 텐서의 채널 수                       |\n",
        "| `out_channels`            | 출력 채널 수 (shortcut 포함 최종 출력)       |\n",
        "| `bottleneck_channels`     | 중간 bottleneck 레이어의 채널 수 (작은 값)    |\n",
        "| `stride`                  | 다운샘플링 여부 (1 또는 2)                 |\n",
        "| `dilation`                | Atrous convolution을 위한 dilation 값 |\n",
        "| `use_bounded_activations` | ReLU6와 clip 연산을 사용할지 여부 (양자화에 유리) |\n"
      ],
      "metadata": {
        "id": "Ki-alkh0TgBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Bottleneck(nn.Module): # ResNet의 Bottleneck 블록을 나타냄\n",
        "    def __init__(self, in_channels, out_channels, bottleneck_channels, stride=1,\n",
        "                 dilation=1, use_bounded_activations=False):\n",
        "        super(Bottleneck, self).__init__()\n",
        "\n",
        "        self.use_bounded_activations = use_bounded_activations\n",
        "        self.stride = stride\n",
        "\n",
        "        # 1x1 conv: dimension reduction 채널 수 감소.\n",
        "        self.conv1 = nn.Conv2d(in_channels, bottleneck_channels, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(bottleneck_channels)\n",
        "\n",
        "        # 3x3 conv: feature extraction 특성 추출\n",
        "        self.conv2 = nn.Conv2d(bottleneck_channels, bottleneck_channels, kernel_size=3,\n",
        "                               stride=stride, padding=dilation, dilation=dilation, bias=False) # stride가 2이면 downsampling 수행\n",
        "        self.bn2 = nn.BatchNorm2d(bottleneck_channels)\n",
        "\n",
        "        # 1x1 conv: dimension restore 채널 복원, 활성화 함수 없음\n",
        "        self.conv3 = nn.Conv2d(bottleneck_channels, out_channels, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # Shortcut (identity or projection)\n",
        "        if in_channels != out_channels or stride != 1:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            ) # 입력 채널 수와 출력 채널 수가 다르거나 stride가 2인 경우 1x1 Conv + BN으로 shape을 맞춰줌\n",
        "        else:\n",
        "            self.shortcut = nn.Identity() # 그렇지 않으면 그대로 shortcut 연결\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = self.shortcut(x) # 입력 x를 shortcut경로로 보냄\n",
        "\n",
        "        # Conv -> BatchNorm -> ReLu6\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = F.relu6(out) if self.use_bounded_activations else F.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = F.relu6(out) if self.use_bounded_activations else F.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        out += shortcut\n",
        "        if self.use_bounded_activations: # True면 clip_by_value와 유사한 torch.clamp로 -6~6 사이로 값 제한\n",
        "            out = torch.clamp(out, -6.0, 6.0)\n",
        "            out = F.relu6(out)\n",
        "        else:\n",
        "            out = F.relu(out)\n",
        "        return out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-qPb6evTd51",
        "outputId": "2e3b96bf-8217-4245-fafe-73e9d46aa29f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 256, 56, 56])\n"
          ]
        }
      ]
    }
  ]
}